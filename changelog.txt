# 1.0.3 (SNAPSHOT)
   - jcp-ai-openai uses as base library `com.openai:openai-java:3.0.3`
   - jcp-ai-anthropic uses as base library `com.anthropic:anthropic-java:2.5.1`

# 1.0.2 (13-aug-2025)
   - fixed truncation for prompt cache files
   - jcp-ai-anthropic uses as base library `com.anthropic:anthropic-java:2.5.0`
   - jcp-ai-gemini uses as base library `com.google.genai:google-genai:1.11.0`
   - jcp-ai-openai uses as base library `com.openai:openai-java:3.0.2`

# 1.0.1 (02-aug-2025)
   - refactor hint cache key handling to take distillation flag, system text and model name into account
   - jcp-ai-gemini uses as base library `com.google.genai:google-genai:1.10.0`
   - jcp-ai-anthropic uses as base library `com.anthropic:anthropic-java:2.2.0`
   - jcp-ai-openai uses as base library `com.openai:openai-java:2.20.1`
   - added test cases for DeepSeek and OpenRouter
   - added boolean flag `jcpai.prompt.distillate.response` to disable postprocessing of LLM response to extract code , by default it is turned on
   - improved prompt cache file processing, added threshold to remove old responses and variable `jcpai.prompt.cache.file.gc.threshold` to define unuse level

# 1.0.0 (22-jul-2025)
   - added adapter `com.igormaznitsa:jcp-ai-anthropic:1.0.0`
   - added adapter `com.igormaznitsa:jcp-ai-gemini:1.0.0`
   - added adapter `com.igormaznitsa:jcp-ai-openai:1.0.0`
